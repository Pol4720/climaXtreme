# Usar Python slim con Java para PySpark
FROM python:3.11-slim-bookworm

# Instalar Java y dependencias del sistema (usando bookworm que tiene openjdk-17)
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        openjdk-17-jdk-headless \
        procps \
        curl && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Configurar JAVA_HOME
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH="${JAVA_HOME}/bin:${PATH}"

WORKDIR /app

# Copiar requirements
COPY Tools/requirements-docker.txt /app/requirements.txt

# Instalar dependencias Python (con cache de pip)
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --upgrade pip && \
    pip install pyspark==3.5.0 && \
    pip install -r /app/requirements.txt && \
    pip install pycountry pycountry-convert

# Copiar el c√≥digo del proyecto
COPY Tools /app/Tools

# Instalar el paquete climaxtreme
WORKDIR /app/Tools
RUN pip install -e . || pip install .

# Volver al directorio de trabajo principal
WORKDIR /app

# Por defecto, mantener el contenedor vivo
CMD ["tail", "-f", "/dev/null"]
